---
title: "STAC <> Zarr Report"
subtitle: "Approaches to integrating STAC and Zarr"
---

# Background + Motivation

STAC (SpatioTemporal Asset Catalogs) is a specification for defining and searching any type of data that has spatial and temporal dimensions. STAC has seen significant adoption in the earth observation community. Zarr is a specification for storing groups of cloud-optimized arrays. Zarr has been adopted by the earth modeling community (led by Pangeo). Both STAC and Zarr offer a flexible nested structure with arbitrary metadata at a variety of levels -- for STAC: catalog, collection, item, asset, for Zarr: group, array. This flexibility has contributed to their popularity, but can also make it hard to tell what they are designed to be particularly good at.

## Comparison Table

The main thing to keep in mind is that Zarr is a data format and STAC is not. Sometimes we conflate "STAC" with "COGs stored in a STAC catalog", but STAC can be used to catalog anything as long as it has spatial temporal dimensions.

| STAC | Zarr |
| -- | --- |
| for data with spatial and temporal dimensions | for groups of arrays |
| supports arbitrary metadata for catalogs, collections, items, assets | supports arbitrary metadata for groups, arrays |
| good at search and discovery | good at filtering within a dataset |
| searching returns items | filtering returns chunks |
| storage of STAC metadata is completely decoupled from storage of data | storage of metadata is coupled to data (i.e., in the same directory, except when virtualized) |

## Typical approach to storing data cubes in STAC

This is the most common approach for organizing datacubes with STAC:

    1. Create a COG for each band at each time and place (in satellite terminology: each scene)
    2. Define a STAC collection for each dataset (i.e., set of data collected using the same platform, algorithms, model, etc).
    3. Define a STAC item for each unique temporal and regional extent within that dataset.
    4. In each STAC item include assets for each variable or band with href links to the COGs containing that data.

This is great for [Level 1 or Level 2 data](https://www.earthdata.nasa.gov/learn/earth-observation-data-basics/data-processing-levels) which tends to not be aligned and are potentially on different reference systems. When applied to Level 3 or Level 4 data this approach has downsides:

    * Client libraries need to scan the metadata for each file in order to lazily load the data cube, which can result in lots of GET requests.
    * Users need to use client libraries for concatenation (e.g., stacstack vs odc.stac) which can lead to confusion and bad data.

## New Approaches

- The [Data Producers section](./data-producers) explores approaches for how to store data cubes using Zar + STAC.
- The [Data Consumers section](./data-consumers) deals with how to reproducibly consume data cubes stored in Zarr + STAC.

## Goals

This report will discuss the partially overlapping goals of STAC and Zarr and offer suggestions for how to use them together. Answering questions like:
 - What do each of these specifications excel at?
 - How can they be used together to get the maximum benefit out of both?
 - Where do virtualized datasets (kerchunk references and Icechunk virtual stores produced by VirtualiZarr) fit in?


## Based off of the following discussions:
 - https://discourse.pangeo.io/t/stac-and-earth-systems-datasets/1472
 - https://discourse.pangeo.io/t/pangeo-showcase-high-performance-python-stac-tooling-backed-by-rust-feb-5-2025/4847
 - https://github.com/cloudnativegeo/cloud-optimized-geospatial-formats-guide/issues/134
 - https://github.com/stac-utils/xpystac/pull/33#issuecomment-1785892112
